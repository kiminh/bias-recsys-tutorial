{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Notebook #1: Designing and evaluating a recommendation algorithm\n",
    "\n",
    "In this notebook, we become familiar with the Python recommendation toolbox, in the simplest possible way. First, we setup the working environment in GDrive. Then, we go through the experimental pipeline, by:\n",
    "- loading the Movielens 1M dataset; \n",
    "- performing a train-test splitting;\n",
    "- creating a pointwise / pairwise / random / mostpop recommendation object;\n",
    "- training the model (if applicable);\n",
    "- computing the user-item relevance matrix;\n",
    "- calculating some of the recommendation metrics (e.g., NDCG, Item Coverage, Diversity, Novelty).\n",
    "\n",
    "The trained models, together with the partial computation we will save (e.g., user-item relevance matrix or metrics), will be the starting point of the investigation and the treatment covered by the other Jupyter notebooks.\n",
    "\n",
    "**IMPORTANT**: Please go the \"Runtime\" option in the top menu, then click on \"Change runtime\" and select \"GPU\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the working environment for this notebook\n",
    "\n",
    "- Python 3.6\n",
    "- Package Requirements: matplotlib, numpy, pandas, scikit-learn, scipy, tensorflow-gpu==2.0\n",
    "- Storage requirements: around 1GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step serves to mount GDrive storage within this Jupyter notebook. The command will request us to give access permissions to this notebook, so that we will be able to clone the project repository when we desire. Please follow the prompted instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clone the project repository in our My Drive folder. If you wish to change the target folder, please modify the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/gdrive/My Drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/mirkomarras/bias-recsys-tutorial.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will move to the project folder in order to install the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd bias-recsys-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will configure the notebooks directory as our working directory in order to simulate a local notebook execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.train_test_splitter import *\n",
    "from models.pointwise import PointWise\n",
    "from models.pairwise import PairWise\n",
    "from models.mostpop import MostPop\n",
    "from models.random import Random\n",
    "from helpers.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the folders where we will store our pre-computed results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '../data/outputs'\n",
    "!mkdir '../data/outputs/splits'\n",
    "!mkdir '../data/outputs/instances'\n",
    "!mkdir '../data/outputs/models'\n",
    "!mkdir '../data/outputs/predictions'\n",
    "!mkdir '../data/outputs/metrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the Movielens 1M dataset, which has been pre-arranged in order to comply with the following structure: user_id, item_id, rating, timestamp, type (label for the item category), and type_id (unique id of the item category). For the sake of tutorial easiness, we assume here that each item is randomly assigned to one of its categories in the original dataset. Our toolbox is flexible enough to integrate any other dataset in csv format that has the same structure of the pre-arranged csv shown below. No further changes are needed to experiment with other datasets.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ml1m'  \n",
    "user_field = 'user_id'\n",
    "item_field = 'item_id'\n",
    "rating_field = 'rating'\n",
    "time_field = 'timestamp'\n",
    "type_field = 'type_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, 'datasets/' + dataset + '.csv'), encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "      <th>type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-12-31 23:12:40</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-12-31 22:33:33</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-12-31 00:49:39</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-12-30 19:01:19</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-12-30 07:41:11</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating            timestamp   type  type_id\n",
       "0        1     1193     5.0  2000-12-31 23:12:40  Drama        7\n",
       "1        2     1193     5.0  2000-12-31 22:33:33  Drama        7\n",
       "2       12     1193     4.0  2000-12-31 00:49:39  Drama        7\n",
       "3       15     1193     4.0  2000-12-30 19:01:19  Drama        7\n",
       "4       17     1193     5.0  2000-12-30 07:41:11  Drama        7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this tutorial, we will simulate a scenario with implicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[rating_field] = data[rating_field].apply(lambda x: 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data in train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **smode**: 'uftime' for fixed timestamp split, 'utime' for time-based split per user, 'urandom' for random split per user \n",
    "- **train_ratio**: percentage of data to be included in the train set\n",
    "- **min_train**: minimum number of train samples for a user to be included  \n",
    "- **min_test**: minimum number of test samples for a user to be included\n",
    "- **min_time**: start timestamp for computing the splitting timestamp (only for uftime)\n",
    "- **max_time**: end timestamp for computing the splitting timestamp (only for uftime)\n",
    "- **step_time**: timestamp step for computing the splitting timestamp (only for uftime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "smode = 'utime'\n",
    "train_ratio = 0.80        \n",
    "min_train_samples = 8\n",
    "min_test_samples = 2\n",
    "min_time = None\n",
    "max_time = None\n",
    "step_time = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this tutorial, we will work with a common time-based split per user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Parsing user 6000 of 6040\n"
     ]
    }
   ],
   "source": [
    "if smode == 'uftime':\n",
    "    traintest = fixed_timestamp(data, min_train_samples, min_test_samples, min_time, max_time, step_time, user_field, item_field, time_field, rating_field)\n",
    "elif smode == 'utime':\n",
    "    traintest = user_timestamp(data, train_ratio, min_train_samples+min_test_samples, user_field, item_field, time_field)\n",
    "elif smode == 'urandom':\n",
    "    traintest = user_random(data, train_ratio, min_train_samples+min_test_samples, user_field, item_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that user_ids and item_ids have been scaled so that user_ids is in [0, no_users] and item_ids will be in [0, no_items]. If you wish to link these new ids to the older ones, please refer to the user_id_original and item_id_original columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "      <th>type_id</th>\n",
       "      <th>set</th>\n",
       "      <th>user_id_original</th>\n",
       "      <th>item_id_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34073</th>\n",
       "      <td>0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000-12-31 23:00:19</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31152</th>\n",
       "      <td>0</td>\n",
       "      <td>1574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000-12-31 23:00:55</td>\n",
       "      <td>Romance</td>\n",
       "      <td>13</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37339</th>\n",
       "      <td>0</td>\n",
       "      <td>957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000-12-31 23:00:55</td>\n",
       "      <td>Children's</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23270</th>\n",
       "      <td>0</td>\n",
       "      <td>1178</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000-12-31 23:00:55</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>14</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28157</th>\n",
       "      <td>0</td>\n",
       "      <td>2147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000-12-31 23:01:43</td>\n",
       "      <td>Romance</td>\n",
       "      <td>13</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  rating            timestamp        type  type_id  \\\n",
       "34073        0     2969     1.0  2000-12-31 23:00:19       Drama        7   \n",
       "31152        0     1574     1.0  2000-12-31 23:00:55     Romance       13   \n",
       "37339        0      957     1.0  2000-12-31 23:00:55  Children's        3   \n",
       "23270        0     1178     1.0  2000-12-31 23:00:55      Sci-Fi       14   \n",
       "28157        0     2147     1.0  2000-12-31 23:01:43     Romance       13   \n",
       "\n",
       "         set  user_id_original  item_id_original  \n",
       "34073  train                 1              3186  \n",
       "31152  train                 1              1721  \n",
       "37339  train                 1              1022  \n",
       "23270  train                 1              1270  \n",
       "28157  train                 1              2340  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of replicability and efficiency of this tutorial, we will save the pre-computed train and test sets in ./data/outputs/splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest.to_csv(os.path.join(data_path, 'outputs/splits/' + dataset + '_' + smode + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create two dataframes, one with train feedback and another with test feedback, from the pre-computed split data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = traintest[traintest['set']=='train'].copy()\n",
    "test = traintest[traintest['set']=='test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(np.unique(traintest[user_field].values))\n",
    "items = list(np.unique(traintest[item_field].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users), len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_per_item = traintest.drop_duplicates(subset=['item_id'], keep='first')[type_field].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(category_per_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of easiness, we will focus on four main recommendation strategies: \n",
    "- Random\n",
    "- MostPop\n",
    "- PointWise\n",
    "- PairWise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = {'random': Random, 'mostpop': MostPop, 'pointwise': PointWise, 'pairwise': PairWise} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to initialize the model. We will see how the process works for a PairWise algorithm. Then, we will consider the other ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing user, item, and categories lists\n",
      "Initializing observed, unobserved, and predicted relevance scores\n",
      "Initializing item popularity lists\n",
      "Initializing category per item\n",
      "Initializing category preference per user\n",
      "Initializing metrics\n"
     ]
    }
   ],
   "source": [
    "model_type = 'pairwise'\n",
    "model = PairWise(users, items, train, test, category_per_item, item_field, user_field, rating_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model by feeding the train data we previously prepared, with the following default values. \n",
    "\n",
    "- **no_epochs** (default: 100)\n",
    "- **batches** (default: 1024)\n",
    "- **lr** (default: 0.001)\n",
    "- **no_factors** (default: 10)\n",
    "- **no_negatives** (default: 10)\n",
    "- **val_split** (default: 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training instances of type pair\n",
      "Computing instances for interaction 800000 / 803798 of type pair60000 / 803798 of type pair 70000 / 803798 of type pair 220000 / 803798 of type pair 730000 / 803798 of type pair\n",
      "Performing training - Epochs 5 Batch Size 1024 Learning Rate 0.001 Factors 10 Negatives 10 Mode pair\n",
      "Train on 7957600 samples\n",
      "7957600/7957600 [==============================] - 25s 3us/sample - loss: 0.1907\n",
      "Validation accuracy: 0.8651016862289221 (Sample 80000 of 80380 )\n",
      "Train on 7957600 samples\n",
      "Epoch 2/2\n",
      "7957600/7957600 [==============================] - 25s 3us/sample - loss: 0.1286\n",
      "Train on 7957600 samples\n",
      "Epoch 3/3\n",
      "7957600/7957600 [==============================] - 25s 3us/sample - loss: 0.1086\n",
      "Train on 7957600 samples\n",
      "Epoch 4/4\n",
      "7957600/7957600 [==============================] - 27s 3us/sample - loss: 0.0961\n",
      "Train on 7957600 samples\n",
      "Epoch 5/5\n",
      "7957600/7957600 [==============================] - 25s 3us/sample - loss: 0.0877\n",
      "Validation accuracy: 0.9182260221747228 (Sample 80000 of 80380 ) 0.9152149886848061 (Sample 19000 of 80380 ) 0.9183020424489388 (Sample 40000 of 80380 ) 0.9179478937876109 (Sample 56000 of 80380 )\n"
     ]
    }
   ],
   "source": [
    "model.train(no_epochs=5) # For the sake of tutorial efficiency, we force to stop after 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the trained model looks as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "UserInput (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PosItemInput (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NegItemInput (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "UserEmb (Embedding)             (None, 1, 10)        60410       UserInput[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ItemEmb (Embedding)             (None, 1, 10)        37070       PosItemInput[0][0]               \n",
      "                                                                 NegItemInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "FlatUserEmb (Flatten)           (None, 10)           0           UserEmb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FlatPosItemEmb (Flatten)        (None, 10)           0           ItemEmb[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FlatNegItemEmb (Flatten)        (None, 10)           0           ItemEmb[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Accuracy (Lambda)               (None, 1)            0           FlatUserEmb[0][0]                \n",
      "                                                                 FlatPosItemEmb[0][0]             \n",
      "                                                                 FlatNegItemEmb[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 97,480\n",
      "Trainable params: 97,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute user-item relevance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use the pre-trained model to predict the user-item relevance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for user 6000 / 6040"
     ]
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, the predicted scores are stored in a matrix of shape np_users x no_items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can access to the relevance score of the user 120 for the item 320 as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7350480556488037"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id, item_id = 120, 320\n",
    "scores[user_id, item_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of convenience, we will save the predicted scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(scores, os.path.join(data_path, 'outputs/predictions/' + dataset + '_' + smode + '_' + model_type + '_scores.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we leverage the predicted scores in order to compute a set of common recommendation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.array([5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_group = load_obj(os.path.join(data_path, 'datasets', 'ml1m-item-group')) \n",
    "# we discuss this point in detail in the third notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics for user 6000 / 6040"
     ]
    }
   ],
   "source": [
    "model.test(item_group=item_group, cutoffs=cutoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method has pre-computed a set of metrics and saved the corresponding values in a Python dictionary, as detailed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['precision', 'recall', 'ndcg', 'hit', 'mean_popularity', 'diversity', 'novelty', 'item_coverage', 'visibility', 'exposure'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for each metrics have been computed and store for each cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6040) precision\n",
      "(6, 6040) recall\n",
      "(6, 6040) ndcg\n",
      "(6, 6040) hit\n",
      "(6, 6040) mean_popularity\n",
      "(6, 6040) diversity\n",
      "(6, 6040) novelty\n",
      "(6, 3706) item_coverage\n",
      "(6, 6040) visibility\n",
      "(6, 6040) exposure\n"
     ]
    }
   ],
   "source": [
    "for name, values in metrics.items():\n",
    "    print(values.shape, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can access to the NDCG score for the user 120 at cutoff 10, with the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41125017975368"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id, cutoff_index = 1324, int(np.where(cutoffs == 10)[0])\n",
    "metrics['ndcg'][cutoff_index, user_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of convenience, we will save the compted metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(metrics, os.path.join(data_path, 'outputs/metrics/' + dataset + '_' + smode + '_' + model_type + '_metrics.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the aggregated values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1176 \n",
      "Recall: 0.0485 \n",
      "NDCG: 0.1272 \n",
      "Hit Rate: 0.5182 \n",
      "Avg Popularity: 1949.2307 \n",
      "Category Diversity: 0.3261 \n",
      "Novelty: 1.7604 \n",
      "Item Coverage: 0.22 \n",
      "User Coverage: 0.5182\n",
      "Minority Exposure: 0.0425\n",
      "Minority Visibility: 0.0418\n"
     ]
    }
   ],
   "source": [
    "model.show_metrics(index_k=int(np.where(cutoffs == 10)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the experimental pipeline for Random and MostPop (optionally for PointWise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a utility function to perform ll the above operations jointly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_type, no_epochs=None):\n",
    "    print('Running model', model_type)\n",
    "    model = model_types[model_type](users, items, train, test, category_per_item, item_field, user_field, rating_field)\n",
    "    model.train(no_epochs=no_epochs) if no_epochs else model.train() \n",
    "    model.predict()\n",
    "    scores = model.get_predictions()\n",
    "    save_obj(scores, os.path.join(data_path, 'outputs/predictions/' + dataset + '_' + smode + '_' + model_type + '_scores.pkl'))\n",
    "    model.test(item_group=item_group, cutoffs=cutoffs)\n",
    "    metrics = model.get_metrics()\n",
    "    save_obj(metrics, os.path.join(data_path, 'outputs/metrics/' + dataset + '_' + smode + '_' + model_type + '_metrics.pkl'))\n",
    "    print()\n",
    "    model.show_metrics(index_k=int(np.where(cutoffs == 10)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model random\n",
      "Initializing user, item, and categories lists\n",
      "Initializing observed, unobserved, and predicted relevance scores\n",
      "Initializing item popularity lists\n",
      "Initializing category per item\n",
      "Initializing category preference per user\n",
      "Initializing metrics\n",
      "Computing metrics for user 6000 / 604060406040/ 60402122 / 6040 / 6040 2687 / 6040 2918 / 60406040 4274 / 6040 6040 / 6040 / 6040 / 6040\n",
      "Precision: 0.0104 \n",
      "Recall: 0.0031 \n",
      "NDCG: 0.0109 \n",
      "Hit Rate: 0.0887 \n",
      "Avg Popularity: 197.8719 \n",
      "Category Diversity: 0.3296 \n",
      "Novelty: 6.9899 \n",
      "Item Coverage: 1.0 \n",
      "User Coverage: 0.0887\n",
      "Minority Exposure: 0.1662\n",
      "Minority Visibility: 0.1658\n"
     ]
    }
   ],
   "source": [
    "run_model('random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model mostpop\n",
      "Initializing user, item, and categories lists\n",
      "Initializing observed, unobserved, and predicted relevance scores\n",
      "Initializing item popularity lists\n",
      "Initializing category per item\n",
      "Initializing category preference per user\n",
      "Initializing metrics\n",
      "Computing metrics for user 6000 / 60406040040 / 6040 1294 / 60402402 / 6040 6040/ 6040 4495 / 6040 / 60405031 / 6040/ 6040 6040\n",
      "Precision: 0.1007 \n",
      "Recall: 0.0384 \n",
      "NDCG: 0.1096 \n",
      "Hit Rate: 0.4422 \n",
      "Avg Popularity: 2328.0848 \n",
      "Category Diversity: 0.3293 \n",
      "Novelty: 1.3922 \n",
      "Item Coverage: 0.03 \n",
      "User Coverage: 0.4422\n",
      "Minority Exposure: 0.0509\n",
      "Minority Visibility: 0.0616\n"
     ]
    }
   ],
   "source": [
    "run_model('mostpop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model pointwise\n",
      "Initializing user, item, and categories lists\n",
      "Initializing observed, unobserved, and predicted relevance scores\n",
      "Initializing item popularity lists\n",
      "Initializing category per item\n",
      "Initializing category preference per user\n",
      "Initializing metrics\n",
      "Generating training instances of type point\n",
      "Computing instances for interaction 800000 / 803798 of type point80000 / 803798 of type point\n",
      "Performing training - Epochs 5 Batch Size 1024 Learning Rate 0.001 Factors 10 Negatives 10 Mode point\n",
      "Train on 7957600 samples, validate on 884178 samples\n",
      "Epoch 1/5\n",
      "7957600/7957600 [==============================] - 60s 8us/sample - loss: 0.2087 - val_loss: 0.2339\n",
      "Epoch 2/5\n",
      "7957600/7957600 [==============================] - 57s 7us/sample - loss: 0.1739 - val_loss: 0.2384\n",
      "Epoch 3/5\n",
      "7957600/7957600 [==============================] - 60s 8us/sample - loss: 0.1647 - val_loss: 0.2378\n",
      "Epoch 00003: early stopping\n",
      "Computing metrics for user 6000 / 60406040\n",
      "Precision: 0.1166 \n",
      "Recall: 0.0591 \n",
      "NDCG: 0.1298 \n",
      "Hit Rate: 0.5541 \n",
      "Avg Popularity: 1408.3628 \n",
      "Category Diversity: 0.3212 \n",
      "Novelty: 2.3554 \n",
      "Item Coverage: 0.35 \n",
      "User Coverage: 0.5541\n",
      "Minority Exposure: 0.0541\n",
      "Minority Visibility: 0.0574\n"
     ]
    }
   ],
   "source": [
    "run_model('pointwise', no_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to extend the toolbox\n",
    "\n",
    "- New splitter: take a look at the helpers/train_test_splitter.py file and how the existing generators have been defined. \n",
    "- New train instances creator: similarly, take a look at the helpers/instances_creator.py file and how the existing generators have been defined. \n",
    "- New model: a new subclass of the Model class defined in models/model.py should be defined, implementing a 'train' and a 'predict' method. \n",
    "- New metrics: both the 'test' and 'show_metrics' methods of models/model.py should be extended with the computation needed by the new metric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
